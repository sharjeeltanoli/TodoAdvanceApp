# Python Structured Logging Template for FastAPI
# Uses structlog for JSON-formatted, context-rich logging.
#
# Install: pip install structlog python-json-logger uvicorn
#
# Variables:
#   {{APP_NAME}}    - Application name (e.g., hackathon-todo-backend)
#   {{LOG_LEVEL}}   - Default log level (e.g., INFO)
#   {{ENVIRONMENT}} - Environment name (e.g., production)

# === File: backend/app/logging_config.py ===

import logging
import sys
import uuid
from contextvars import ContextVar
from typing import Any

import structlog

# Context variable for request-scoped data
request_id_ctx: ContextVar[str] = ContextVar("request_id", default="")
user_id_ctx: ContextVar[str] = ContextVar("user_id", default="anonymous")


def setup_logging(
    app_name: str = "{{APP_NAME}}",
    log_level: str = "{{LOG_LEVEL}}",
    environment: str = "{{ENVIRONMENT}}",
) -> None:
    """Configure structured logging for the application."""

    # Shared processors for both structlog and stdlib
    shared_processors: list[structlog.types.Processor] = [
        structlog.contextvars.merge_contextvars,
        structlog.stdlib.add_log_level,
        structlog.stdlib.add_logger_name,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.UnicodeDecoder(),
    ]

    if environment == "production":
        # Production: JSON output for Loki/log aggregation
        renderer = structlog.processors.JSONRenderer()
    else:
        # Development: colored, human-readable output
        renderer = structlog.dev.ConsoleRenderer(colors=True)

    structlog.configure(
        processors=[
            *shared_processors,
            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

    formatter = structlog.stdlib.ProcessorFormatter(
        processors=[
            structlog.stdlib.ProcessorFormatter.remove_processors_meta,
            renderer,
        ],
        foreign_pre_chain=shared_processors,
    )

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(formatter)

    root_logger = logging.getLogger()
    root_logger.handlers.clear()
    root_logger.addHandler(handler)
    root_logger.setLevel(getattr(logging, log_level.upper()))

    # Quiet noisy loggers
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.error").setLevel(logging.INFO)
    logging.getLogger("httpcore").setLevel(logging.WARNING)


def get_logger(name: str) -> structlog.stdlib.BoundLogger:
    """Get a named logger with app context."""
    return structlog.get_logger(name)


# === File: backend/app/middleware/logging_middleware.py ===

import time
import uuid

from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint
from starlette.requests import Request
from starlette.responses import Response

import structlog

# from app.logging_config import request_id_ctx, user_id_ctx, get_logger

logger = get_logger("http")


class LoggingMiddleware(BaseHTTPMiddleware):
    """Middleware that logs every request with structured context."""

    async def dispatch(
        self, request: Request, call_next: RequestResponseEndpoint
    ) -> Response:
        # Generate or extract request ID
        request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
        request_id_ctx.set(request_id)

        # Extract user ID from auth (if available)
        user_id = getattr(request.state, "user_id", "anonymous")
        user_id_ctx.set(str(user_id))

        # Bind context for all logs in this request
        structlog.contextvars.clear_contextvars()
        structlog.contextvars.bind_contextvars(
            request_id=request_id,
            user_id=str(user_id),
            method=request.method,
            path=request.url.path,
            client_ip=request.client.host if request.client else "unknown",
        )

        start_time = time.perf_counter()

        try:
            response = await call_next(request)
            duration_ms = (time.perf_counter() - start_time) * 1000

            logger.info(
                "request.completed",
                status=response.status_code,
                duration_ms=round(duration_ms, 2),
            )

            # Add request ID to response headers for tracing
            response.headers["X-Request-ID"] = request_id
            return response

        except Exception as exc:
            duration_ms = (time.perf_counter() - start_time) * 1000
            logger.error(
                "request.failed",
                error=str(exc),
                error_type=type(exc).__name__,
                duration_ms=round(duration_ms, 2),
            )
            raise


# === File: backend/app/middleware/metrics_middleware.py (Prometheus) ===

# from prometheus_fastapi_instrumentator import Instrumentator
# from prometheus_client import Counter, Histogram
#
# # Custom metrics
# tasks_created = Counter(
#     "tasks_created_total",
#     "Total tasks created",
#     ["user_id"],
# )
# task_operation_duration = Histogram(
#     "task_operation_seconds",
#     "Task operation duration in seconds",
#     ["operation"],
#     buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
# )
# task_operation_errors = Counter(
#     "task_operation_errors_total",
#     "Task operation errors",
#     ["operation"],
# )
# auth_failures = Counter(
#     "auth_failures_total",
#     "Authentication failures",
#     ["method"],
# )
# db_connection_errors = Counter(
#     "db_connection_errors_total",
#     "Database connection errors",
# )
# active_users = Gauge(
#     "active_users",
#     "Currently active users",
# )


# === Usage in route handlers ===

# logger = get_logger("tasks")
#
# @router.post("/tasks")
# async def create_task(task: TaskCreate, user: User = Depends(get_current_user)):
#     logger.info("task.creating", title=task.title, priority=task.priority)
#
#     with task_operation_duration.labels(operation="create").time():
#         try:
#             result = await task_service.create(task, user.id)
#             tasks_created.labels(user_id=str(user.id)).inc()
#             logger.info("task.created", task_id=str(result.id))
#             return result
#         except Exception as e:
#             task_operation_errors.labels(operation="create").inc()
#             logger.error("task.create_failed", error=str(e))
#             raise


# === Integration with FastAPI app ===

# from app.logging_config import setup_logging
# from app.middleware.logging_middleware import LoggingMiddleware
# from prometheus_fastapi_instrumentator import Instrumentator
#
# setup_logging()
#
# app = FastAPI()
# app.add_middleware(LoggingMiddleware)
# Instrumentator().instrument(app).expose(app, endpoint="/metrics")
